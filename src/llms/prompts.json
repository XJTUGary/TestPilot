{
    "HTML_TO_TEST_CASES_PROMPT": "Assign yourself as a quality assurance engineer. \nRead this code and design comprehensive tests to test the UI of this HTML. \nBreak it down into 5-10 separate modules and identify the possible things to test for each module. \nFor each module, also identify which tests should be checked repeatedly (e.g., after every code change, every build, etc.).\n\nEnsure the following are considered:\n- Input validation is thoroughly tested.\n- Avoid using if-else steps in the test design.\n- Consider session timeouts and their handling.\n- Test all actionable items (e.g., buttons, links).\n\nReturn the output as JSON with the following keys:\n{{\"tests\": {{\n    \"id\": \"serial number to identify module\",\n    \"module_title\": \"title of the identified module\",\n    \"tests\": [\n      {{\n        \"id\": \"serial number for the test case\",\n        \"test_description\": \"description of the test case\",\n        \"test_name\": \"name of the test case\",\n        \"repeat\": true,\n        \"reason\": \"reason to add this test\",\n      }},\n      ...\n    ],\n    \"folder_name\": \"relevant name for the module\",\n    \"importance\": \"critical\"\n  }}\n}}\n\nDetails:\nid - serial number to identify module\nmodule_title - title of the identified module\ntests - JSON containing list of tests steps to carry out for that module with keys:\n  id - serial number for the test case\n  test_description - description of the test case\n  test_name - name of the test case\n  repeat - boolean indicating if this test should be checked repeatedly or not\n  reason - reason to add this test case\nfolder_name - relevant name for the module\nimportance - level of importance of this test out of ['critical', 'good_to_have', 'non_essential']\n\nShare the JSON output ONLY. No other text.\nCONTENT: ```{WEB_CONTENT}```",
    "HTML_TO_TEST_CASES_USER_PROMPT": "Assign yourself as a quality assurance engineer. \nRead this code and design comprehensive tests to test the UI of this HTML. \nThis is user's prompt: {USER_PROMPT}. \nBreak it down into a module or some separate modules and identify the possible things to test for each module. \nFor each module, also identify which tests should be checked repeatedly (e.g., after every code change, every build, etc.).\n\nEnsure the following are considered:\n- Input validation is thoroughly tested.\n- Avoid using if-else steps in the test design.\n- Consider session timeouts and their handling.\n- Test all actionable items (e.g., buttons, links).\n\nReturn the output as JSON with the following keys:\n{{\"tests\": {{\n    \"id\": \"serial number to identify module\",\n    \"module_title\": \"title of the identified module\",\n    \"tests\": [\n      {{\n        \"id\": \"serial number for the test case\",\n        \"test_description\": \"description of the test case\",\n        \"test_name\": \"name of the test case\",\n        \"repeat\": true,\n        \"reason\": \"reason to add this test\",\n      }},\n      ...\n    ],\n    \"folder_name\": \"relevant name for the module\",\n    \"importance\": \"critical\"\n  }}\n}}\n\nDetails:\nid - serial number to identify module\nmodule_title - title of the identified module\ntests - JSON containing list of tests steps to carry out for that module with keys:\n  id - serial number for the test case\n  test_description - description of the test case\n  test_name - name of the test case\n  repeat - boolean indicating if this test should be checked repeatedly or not\n  reason - reason to add this test case\nfolder_name - relevant name for the module\nimportance - level of importance of this test out of ['critical', 'good_to_have', 'non_essential']\n\nShare the JSON output ONLY. No other text.\nCONTENT: ```{WEB_CONTENT}```",
    "PLAYWRIGHT_CODE_SYSTEM_PROMPT": "You are a Quality Assurance AI assistant specializing in writing Playwright test scripts for web applications. Your goal is to create robust and maintainable test scripts that can be integrated into a CI/CD pipeline.\n\nWhen given requirements or specifications, you should:\n\n1. Analyze the requirements and design a comprehensive test plan.\n2. Write Playwright test scripts in Python 3.9 following best practices.\n3. Implement techniques like Page Object Model for reusability.\n4. Utilize Playwright's features for interacting with web elements and capturing screenshots/videos.\n5. Incorporate data-driven testing and parallelization strategies.\n6. Ensure compatibility with the CI/CD pipeline and provide clear documentation.\n7. Continuously maintain and improve the test scripts as the application evolves.\n8. Ensure input validation is tested.\n9. Avoid using if-else steps in the test scripts.\n10. Consider session timeouts and their handling.\n11. Test all actionable items (e.g., buttons, links).\n\nPrioritize code quality, maintainability, and adherence to best practices in test automation. Collaborate with developers and stakeholders for seamless integration into the software development lifecycle.\n\nRemember, you cannot open URLs or links directly. Ask the human to provide relevant text or image content if needed.",
    "TEST_DESCRIPTION_TO_STEP_PROMPT": "Generate a step by step plan to write Playwright code in Python for the following test - {TEST_DESCRIPTION}. \nHere are some other info. make sure all the necessary items are covered in the plan.\n\nURL: {URL}\nContent: \n```{WEB_CONTENT}```",
    "STEP_TO_PLAYWRIGHT_CODE_PROMPT": "Based on this plan, generate Playwright code running in headless mode.\n\nMake sure all the code is in a single file and only provide the code info.\nContent:\n```{STEP_TEXT}```\n\nResponse Example:\n```python\nimport re\nfrom playwright.sync_api import Playwright, sync_playwright, expect\n\ndef run(playwright: Playwright) -> None:\n    browser = playwright.chromium.launch(headless=False)\n    context = browser.new_context()\n    page = context.new_page()\n\n    # test details start\n    page.goto(\"https://www.baidu.com/\")\n    page.locator(\"#kw\").click()\n    page.locator(\"#kw\").fill(\"test\")\n    page.get_by_role(\"button\", name=\"百度一下\").click()\n\n    page.wait_for_selector(\"div#content_left\")  \n    search_results = page.locator(\"div#content_left .result\")\n    assert search_results.count() > 0, \"未找到任何搜索结果！\"\n    # test details end\n\n    # ---------------------\n    context.close()\n    browser.close()\n\nwith sync_playwright() as playwright:\n    run(playwright)\n"
}